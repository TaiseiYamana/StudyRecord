{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaiseiYamana/StudyRecord/blob/main/MobileVit_training_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "\n",
        "pytorch cifar100 data auguments: \n",
        "https://github.com/weiaicunzai/pytorch-cifar100\n",
        "\n",
        "MobilVitConfig argument: \n",
        "https://huggingface.co/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"
      ],
      "metadata": {
        "id": "Rqa1Jllvb64_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuL_64MBppg9",
        "outputId": "27c09e3b-e330-4066-9849-582924e60428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MobileViTConfig, MobileViTForImageClassification\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ExponentialLR, CosineAnnealingLR\n",
        "\n",
        "image_size  = 32\n",
        "patch_size = 8 # image_sizeの約数であること\n",
        "n_classes = 100\n",
        "seed = 1\n",
        "\n",
        "lr = 1e-2\n",
        "momentum = 0.9\n",
        "weight_decay = 0.01\n",
        "batch_size = 64\n",
        "\n",
        "# 乱数生成シード値固定設定\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "random.seed(0)\n",
        "cudnn.deterministic = False\n",
        "cudnn.benchmark = True\n",
        "\n",
        "# MobileViTセットアップ\n",
        "configuration = MobileViTConfig(image_size = image_size)\n",
        "model = MobileViTForImageClassification(configuration).from_pretrained(\"apple/mobilevit-small\")\n",
        "#model = MobileViTForImageClassification.from_pretrained(\"apple/mobilevit-small\")\n",
        "model.classifier = nn.Linear(640, n_classes)\n",
        "#torch.nn.init.normal_(model.classifier.weight, mean=0, std=1)\n",
        "#model.classifier.bias.data.fill_(0.01)"
      ],
      "metadata": {
        "id": "iMt9V5iUfQ4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.num_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiEw2Ya30Vkl",
        "outputId": "37de44ba-f19e-417e-96f3-be9b841b4bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5001732"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.5070751592371323, 0.48654887331495095, 0.4409178433670343]\n",
        "std = [0.2673342858792401, 0.2564384629170883, 0.27615047132568404]\n",
        "\n",
        "#test_mean = [0.5088964127604166, 0.48739301317401956, 0.44194221124387256]\n",
        "#test_mean = [0.2682515741720801, 0.2573637364478126, 0.2770957707973042]\n",
        "def RGB_2_BGR(image: torch.Tensor) -> torch.Tensor:\n",
        "    r\"\"\"Convert a RGB image to BGR.\n",
        "\n",
        "    Args:\n",
        "        image: RGB Image to be converted to BGRof of shape :math:`(*,3,H,W)`.\n",
        "\n",
        "    Returns:\n",
        "        BGR version of the image with shape of shape :math:`(*,3,H,W)`.\n",
        "\n",
        "    Example:\n",
        "        >>> input = torch.rand(2, 3, 4, 5)\n",
        "        >>> output = rgb_to_bgr(input) # 2x3x4x5\n",
        "    \"\"\"\n",
        "    if not isinstance(image, torch.Tensor):\n",
        "        raise TypeError(f\"Input type is not a torch.Tensor. Got {type(image)}\")\n",
        "\n",
        "    if len(image.shape) < 3 or image.shape[-3] != 3:\n",
        "        raise ValueError(f\"Input size must have a shape of (*, 3, H, W).Got {image.shape}\")\n",
        "    out: torch.Tensor = image.flip(-3)\n",
        "    return out\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(image_size, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.ToTensor(),\n",
        "            RGB_2_BGR()\n",
        "            transforms.Normalize(mean, std)])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)])\n",
        "\n",
        "train_dataset = CIFAR100(root = './', train = True, transform = train_transform, download = True)\n",
        "testTrain_dataset = CIFAR100(root = './', train = True, transform = test_transform, download = True)\n",
        "test_dataset = CIFAR100(root = './', train = False, transform = test_transform, download = True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "testTrain_loader = DataLoader(testTrain_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "test_loader_dict = {'Train': testTrain_loader, 'Test': test_loader}"
      ],
      "metadata": {
        "id": "1KJRxPa-vyr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = []\n",
        "for name,param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params.append(param)\n",
        "\n",
        "#optimizer = optim.SGD([\n",
        "#        {'params':  params[:-2], 'lr':1.0*lr},\n",
        "#        {'params':  params[-1], 'lr':10.0*lr}\n",
        "#    ], lr=lr, momentum=momentum)\n",
        "\n",
        "\n",
        "optimizer = optim.AdamW([\n",
        "        {'params':  params[:-2], 'lr':1.0*lr},\n",
        "        {'params':  params[-1], 'lr':10.0*lr}\n",
        "        ], lr = lr, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "#scheduler = ExponentialLR(optimizer, gamma=0.95)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=0.001)"
      ],
      "metadata": {
        "id": "N9HtcvqESbDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_combination(x, y, epsilon):\n",
        "    return (1 - epsilon) * x + epsilon * y\n",
        "\n",
        "def reduce_loss(loss, reduction='mean'):\n",
        "    return loss.mean() if reduction == 'mean' else loss.sum() if reduction == 'sum' else loss\n",
        "\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, epsilon=0.1, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, preds, target):\n",
        "        n = preds.size()[-1]\n",
        "        log_preds = F.log_softmax(preds, dim=-1)\n",
        "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
        "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
        "        return linear_combination(nll, loss/n, self.epsilon)\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion, device):\n",
        "  model.train()\n",
        "\n",
        "  for ite, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs).logits\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "def test(model, test_loader_dict, phase, device):\n",
        "  model.eval()\n",
        "  test_loss = 0.0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in test_loader_dict[phase]:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      outputs = model(inputs).logits\n",
        "      test_loss += F.cross_entropy(outputs, labels, size_average=False).item()\n",
        "\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      correct += torch.sum(preds == labels.data)\n",
        "      \n",
        "    test_loss /= len(test_loader_dict[phase].dataset)\n",
        "    test_acc = correct / len(test_loader_dict[phase].dataset)\n",
        "\n",
        "    print(f'{phase} loss : {test_loss:.4f} acc : {test_acc:.4f}')\n",
        "  return test_loss, test_acc"
      ],
      "metadata": {
        "id": "VHKZlHYE1UuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUが使用できるかを確認\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "criterion = LabelSmoothingCrossEntropy()\n",
        "\n",
        "history = {}\n",
        "history['train_loss'] = []\n",
        "history['train_acc'] = []\n",
        "history['test_loss'] = []\n",
        "history['test_acc'] = []\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    print('-----------------------')\n",
        "    print('Epoch {}/{}, lr: {}'.format(epoch,num_epochs, optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "    train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = test(model, test_loader_dict, 'Train', device)\n",
        "    test_loss, test_acc = test(model, test_loader_dict, 'Test', device)\n",
        "\n",
        "    #scheduler.step() \n",
        "\n",
        "    history['train_loss'].append(val_loss)\n",
        "    history['train_acc'].append(val_acc.to('cpu').item())\n",
        "    history['test_loss'].append(test_loss)\n",
        "    history['test_acc'].append(test_acc.to('cpu').item())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7p14yneDuafj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as col\n",
        "\n",
        "def plot_graph(values1, values2, rng, label1, label2):\n",
        "    plt.plot(range(rng), values1, label=label1)\n",
        "    plt.plot(range(rng), values2, label=label2)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()  "
      ],
      "metadata": {
        "id": "Kyf6Aza4sRB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graph(history['train_acc'], history['test_acc'], num_epochs,'train_acc', 'test_acc')"
      ],
      "metadata": {
        "id": "lMKX3Sc7sSAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graph(history['train_loss'], history['test_loss'], num_epochs,'train_loss', 'test_loss')"
      ],
      "metadata": {
        "id": "gtp91Tt6VowB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}